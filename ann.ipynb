{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron\n",
    "## (Aritifical Neural Network / Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Load dataset and split the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/wine.csv\")\n",
    "# df = df.drop(\"Wine\", axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "\n",
    "y_fitting = df[\"Proline\"].to_numpy(dtype=float)\n",
    "X_fitting = df[[\"Alcohol\", \"Phenols\", \"Flavanoids\", \"Nonflavanoid.phenols\"]].to_numpy(dtype=float)      \n",
    "\n",
    "print(np.shape(X_fitting), np.shape(y_fitting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the some values are quite weird, we have to mmodify them\n",
    "# X_fitting[:, 1] *= 10.0     # Volatile Acidity\n",
    "# X_fitting[:, 2] *= 10.0     # Citric Acid\n",
    "# X_fitting[:, 4] *= 100.0    # Chlorine\n",
    "# X_fitting[:, 5] /= 5        # Free Sulfur Dioxide\n",
    "# X_fitting[:, 6] /= 5        # Total Sulfur Dioxide\n",
    "\n",
    "X_fitting[:, 0] -= 13.0     # Alcohol\n",
    "y_fitting[:] /= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(X_fitting[:, 5] * 5, y_fitting, color = \"blue\")\n",
    "# plt.xlabel(\"Free Sulfur Dioxide\")\n",
    "# plt.ylabel(\"Quality\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.scatter(X_fitting[:, 3], y_fitting, color = \"blue\")\n",
    "# plt.xlabel(\"Residual Sugar\")\n",
    "# plt.ylabel(\"Quality\")\n",
    "# plt.show()\n",
    "\n",
    "plt.scatter(X_fitting[:, 0] * 5, y_fitting, color = \"blue\")\n",
    "plt.xlabel(\"Alcohol\")\n",
    "plt.ylabel(\"Proline\")\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(X_fitting[:, 1], y_fitting, color = \"blue\")\n",
    "plt.xlabel(\"Phenols\")\n",
    "plt.ylabel(\"Proline\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    size = np.shape(x)\n",
    "    for i in range(size[0]):\n",
    "        for j in range(size[1]):\n",
    "            if x[i][j] < 0:\n",
    "                x[i][j] = 0\n",
    "    return x\n",
    "\n",
    "\n",
    "def LeakyReLU(x):\n",
    "    size = np.shape(x)\n",
    "    for i in range(size[0]):\n",
    "        for j in range(size[1]):\n",
    "            if x[i][j] < 0:\n",
    "                x[i][j] *= 0.1\n",
    "    return x\n",
    "\n",
    "\n",
    "# def softMax(x):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossFunc(error):\n",
    "    sum = 0.0\n",
    "    for i in error:\n",
    "        sum += i * i\n",
    "    return sum / 2 / np.size(error[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent\n",
    "# dLoss/dW[2] = dLoss/dY[3] * dY[3]/dZ[2] * dZ[2]/dW[2]\n",
    "#             = Error       * 1           * Y[2]\n",
    "# dLoss/dB[2] = dLoss/dY[3] * dY[3]/dZ[2] * dZ[2]/dB[2]\n",
    "#             = Error       * 1\n",
    "\n",
    "# dLoss/dW[1] = dLoss/dY[3] * dY[3]/dZ[2] * dZ[2]/dY[2] * dY[2]/dZ[1] * dZ[1]/dW[1]\n",
    "#             = Error       * 1           * W[2]        * 1           * Y[1]\n",
    "# dLoss/dB[1] = dLoss/dY[3] * dY[3]/dZ[2] * dZ[2]/dY[2] * dY[2]/dZ[1] * dZ[1]/dB[1]\n",
    "#             = Error       * 1           * W2          * 1\n",
    "\n",
    "# dLoss/dW[0] = dLoss/dY[3] * dY[3]/dZ[2] * dZ[2]/dY[2] * dY[2]/dZ[1] * dZ[1]/dY[1] * dY[1]/dZ[0] * dZ[0]/dW[0]\n",
    "#             = Error       * 1           * W[2]        * 1           * W[1]        * 1           * Y[0]\n",
    "# dLoss/dB[0] = dLoss/dY[3] * dY[3]/dZ[2] * dZ[2]/dY[2] * dY[2]/dZ[1] * dZ[1]/dB[1] * dY[1]/dZ[0] * dZ[0]/dB[0]\n",
    "#             = Error       * 1           * W2         * 1            * W[1]        * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayerPerceptron(X_calc, y_calc, activeFunc = ReLU, hddn = [5], learning_rate = 0.05):\n",
    "\n",
    "    # Toggle size\n",
    "    size_X = np.shape(X_calc)\n",
    "    size_y = np.shape(y_calc)\n",
    "    if len(size_y) == 1:    # if y contains only one target\n",
    "        size_y = (size_y[0], 1)\n",
    "        y_calc = np.reshape(y_calc, (size_y[0], 1))\n",
    "\n",
    "    # Make all matrix to support the ANN\n",
    "    W = [None for _ in range(len(hddn) + 1)]\n",
    "    B = [None for _ in range(len(hddn) + 1)]\n",
    "    Y = [None for _ in range(len(hddn) + 2)]     # Two\n",
    "\n",
    "    s_iter = [ *[ size_X[1] ], *[ hddn[i] for i in range(len(hddn)) ], *[ size_y[1] ] ]\n",
    "    for i in range(len(W)):\n",
    "        W[i] = np.random.normal(0, 1, size = (s_iter[i], s_iter[i + 1]))\n",
    "        B[i] = np.random.normal(0, 1, size = (1, s_iter[i + 1]))\n",
    "\n",
    "\n",
    "\n",
    "    # For error\n",
    "    y_predicted = np.zeros(size_y[0])\n",
    "    error_points = np.zeros(100)\n",
    "\n",
    "    # Start running\n",
    "    step = 0\n",
    "    while step < 100:\n",
    "\n",
    "        mix = np.random.permutation(size_X[0])\n",
    "        for i in mix:\n",
    "\n",
    "            # Y[0] = X\n",
    "            # Z[0] = Y[0] * W[0] + B[0]\n",
    "            # Y[1] = activeFunc(Z[0])\n",
    "\n",
    "            # Z[1] = Y[1] * W[1] + B[1]\n",
    "            # Y[2] = activeFunc(Z[1])\n",
    "\n",
    "            # Z[2] = Y[2] * W[2] + B[2]\n",
    "            # Y[3] = activeFunc(Z[2])\n",
    "\n",
    "            Y[0] = np.reshape(X_calc[i], (1, size_X[1]))\n",
    "            for j in range(len(hddn) + 1):\n",
    "                z        = np.dot(Y[j], W[j]) + B[j]\n",
    "                Y[j + 1] = np.array(activeFunc(z))\n",
    "\n",
    "            y_predicted[i] = Y[-1]\n",
    "\n",
    "            # dLoss/dW[2] = Y[2] * Error\n",
    "            # dLoss/dW[1] = Y[1] * Error * W[2]\n",
    "            # dLoss/dW[0] = Y[0] * Error * W[2] * W[1]\n",
    "\n",
    "            error = 2 / size_X[0] * (y_predicted[i] - y_calc[i])\n",
    "            for j in range(len(W) - 1, -1, -1):\n",
    "                multi = np.reshape(error, (1, 1))   if (j == len(W) - 1)   else np.dot(multi, W[j + 1].T)\n",
    "                W[j] = W[j] - learning_rate * np.dot(Y[j].T, multi)\n",
    "                B[j] = B[j] - learning_rate * multi\n",
    "            \n",
    "            #print(error)\n",
    "\n",
    "        try:\n",
    "            rmse = mean_squared_error(y_calc, y_predicted, squared = False)\n",
    "            error_points[step] = rmse\n",
    "            step += 1\n",
    "            print(\"Step \", step, \" done with RMSE = \", rmse)\n",
    "        except:\n",
    "            for i in range(len(W)):\n",
    "                W[i] = np.random.normal(0, 1, size = (s_iter[i], s_iter[i + 1]))\n",
    "                B[i] = np.random.normal(0, 1, size = (1, s_iter[i + 1]))\n",
    "            print(\"RESET at step \", step)\n",
    "            step = 0\n",
    "    \n",
    "    plt.plot(np.arange(100), error_points)\n",
    "    plt.show()\n",
    "    \n",
    "    return W, B\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hddn = [12, 10]\n",
    "active_func = ReLU\n",
    "W, B = multilayerPerceptron(X_fitting, y_fitting, hddn = hddn, activeFunc = active_func, learning_rate = 0.0005)\n",
    "#W1, W2, B1, B2 = trainDataMLP(X_train, y_train, learning_rate = 0.5)\n",
    "W, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "def getPredictedY(X_calc, W, B, hddn, activeFunc = ReLU):\n",
    "\n",
    "    size_X = np.shape(X_calc)\n",
    "    y_predicted = [None for _ in range(size_X[0])]\n",
    "    \n",
    "    for i in range(size_X[0]):\n",
    "\n",
    "        Y = [None for _ in range(len(hddn) + 2)]\n",
    "        Y[0] = np.reshape(X_calc[i], (1, np.shape(X_calc)[1]))\n",
    "\n",
    "        for j in range(len(hddn) + 1):\n",
    "            z        = np.dot(Y[j], W[j]) + B[j]\n",
    "            Y[j + 1] = np.array(activeFunc(z))\n",
    "        \n",
    "        y_predicted[i] = Y[-1]\n",
    "    \n",
    "    return y_predicted\n",
    "\n",
    "pred_y = np.array(getPredictedY(X_fitting, W, B, hddn = hddn, activeFunc = active_func))\n",
    "# pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_fitting[:, 0], y_fitting, color = \"blue\")\n",
    "plt.scatter(X_fitting[:, 0], pred_y, color = \"red\")\n",
    "plt.xlabel(\"Alcohol\")\n",
    "plt.ylabel(\"Proline\")\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(X_fitting[:, 1], y_fitting, color = \"blue\")\n",
    "plt.scatter(X_fitting[:, 1], pred_y, color = \"red\")\n",
    "plt.xlabel(\"Phenols\")\n",
    "plt.ylabel(\"Proline\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict all of values\n",
    "true_pos = 0\n",
    "true_neg = 0\n",
    "fals_pos = 0\n",
    "fals_neg = 0\n",
    "\n",
    "for i in range(instan_train):\n",
    "    pred_y = getPredictedY(X_train[i], W1, W2, B1, B2)\n",
    "    if pred_y >= 0.5:   # Prediction is True\n",
    "        if y_train[i] == 1.0:\n",
    "            true_pos += 1\n",
    "        else:\n",
    "            fals_pos += 1\n",
    "    else:\n",
    "        if y_train[i] == 1.0:\n",
    "            fals_neg += 1\n",
    "        else:\n",
    "            true_neg += 1\n",
    "\n",
    "\n",
    "print(true_pos, fals_neg)\n",
    "print(fals_pos, true_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ae58900cfbb8c43ab3495913814b7cf26024f51651a94ce8bf64d6111688e8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
